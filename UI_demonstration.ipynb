{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa58b9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pickle\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Ensure pytesseract is properly configured\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# Load Random Forest model and vectorizer\n",
    "with open(\"spam_model.pkl\", \"rb\") as f:\n",
    "    text_model = pickle.load(f)\n",
    "\n",
    "with open(\"vectorizer.pkl\", \"rb\") as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "\n",
    "# Load CNN logo model (.h5 format)\n",
    "logo_model = load_model(\"cnn_fake_logo_model.h5\")\n",
    "\n",
    "# Weights for text and logo analysis\n",
    "w_text = 0.4  \n",
    "w_logo = 0.6  \n",
    "\n",
    "# Function to classify the uploaded ad\n",
    "def classify_ad(ad_image):\n",
    "    # Step 1: Extract text from the image using OCR\n",
    "    extracted_text = pytesseract.image_to_string(ad_image)\n",
    "\n",
    "    # Step 2: Vectorize the text\n",
    "    transformed_text = vectorizer.transform([extracted_text])\n",
    "\n",
    "    # Step 3: Classify text using Random Forest\n",
    "    text_prediction = text_model.predict(transformed_text)[0]  # 1 (Fake) or 0 (Legitimate)\n",
    "    text_prob = text_model.predict_proba(transformed_text)[0][1]  # Get probability of \"Fake\"\n",
    "    text_result = f\"Fake ({text_prob:.3f})\" if text_prob >= 0.5 else f\"Legitimate ({1 - text_prob:.3f})\"\n",
    "\n",
    "    # Step 4: Preprocess the image for logo classification\n",
    "    if not isinstance(ad_image, Image.Image):\n",
    "        ad_image = Image.fromarray(np.array(ad_image))\n",
    "    ad_image = ad_image.resize((128, 128))  # Example resizing\n",
    "    ad_image = np.array(ad_image) / 255.0  # Normalize the image\n",
    "    ad_image = ad_image.reshape(1, 128, 128, 3)  # Add batch dimension\n",
    "\n",
    "    # Step 5: Classify the logo using the CNN model\n",
    "    logo_prediction = logo_model.predict(ad_image)\n",
    "    logo_prob = logo_prediction[0][0]  # Extract probability of \"Fake\"\n",
    "    logo_result = f\"Fake ({logo_prob:.3f})\" if logo_prob >= 0.5 else f\"Legitimate ({1 - logo_prob:.3f})\"\n",
    "\n",
    "    # Step 6: Compute weighted average score\n",
    "    final_score = (w_text * text_prob) + (w_logo * logo_prob)\n",
    "\n",
    "    # Step 7: Final classification\n",
    "    final_result = f\"Fake ({final_score:.3f})\" if final_score >= 0.5 else f\"Legitimate ({1 - final_score:.3f})\"\n",
    "\n",
    "    return extracted_text, text_result, logo_result, final_result\n",
    "\n",
    "# Gradio Interface\n",
    "interface = gr.Interface(\n",
    "    fn=classify_ad,\n",
    "    inputs=gr.Image(label=\"Upload Advertisement\"),\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"Extracted Text\"),\n",
    "        gr.Textbox(label=\"Text Prediction (With Probability)\"),\n",
    "        gr.Textbox(label=\"Logo Prediction (With Probability)\"),\n",
    "        gr.Textbox(label=\"Final Classification (With Probability)\"),\n",
    "    ],\n",
    "    title=\"Fake Ad Scam Detection\",\n",
    "    description=\"Upload an ad image to detect if it's fake or real based on text and logo analysis using weighted decision-making. Each classification shows confidence probability.\"\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "interface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d59cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
